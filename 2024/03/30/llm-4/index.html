<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="Hexo Theme Redefine">
    
    <meta name="author" content="Julian">
    <!-- preconnect -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    
    
    <!--- Seo Part-->
    
    <link rel="canonical" href="https://higiraffe.github.io/2024/03/30/llm-4/"/>
    <meta name="robots" content="index,follow">
    <meta name="googlebot" content="index,follow">
    <meta name="revisit-after" content="1 days">
    
        <meta property="og:type" content="article">
<meta property="og:title" content="【学习笔记】vLLM">
<meta property="og:url" content="https://higiraffe.github.io/2024/03/30/llm-4/index.html">
<meta property="og:site_name" content="HiGiraffe">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://higiraffe.github.io/images/llm-4/5">
<meta property="og:image" content="https://higiraffe.github.io/images/llm-4/6">
<meta property="og:image" content="https://higiraffe.github.io/images/llm-4/3">
<meta property="og:image" content="https://higiraffe.github.io/images/llm-4/4">
<meta property="og:image" content="https://higiraffe.github.io/images/llm-4/1">
<meta property="og:image" content="https://higiraffe.github.io/images/llm-4/2">
<meta property="og:image" content="https://higiraffe.github.io/images/llm-4/1.gif">
<meta property="og:image" content="https://higiraffe.github.io/images/llm-4/7">
<meta property="og:image" content="https://higiraffe.github.io/images/llm-4/2.gif">
<meta property="og:image" content="https://higiraffe.github.io/images/llm-4/3.gif">
<meta property="og:image" content="https://higiraffe.github.io/images/llm-4/8">
<meta property="og:image" content="https://higiraffe.github.io/images/llm-4/9">
<meta property="og:image" content="https://higiraffe.github.io/images/llm-4/10">
<meta property="og:image" content="https://higiraffe.github.io/images/llm-4/11">
<meta property="og:image" content="https://higiraffe.github.io/images/llm-4/12">
<meta property="og:image" content="https://higiraffe.github.io/images/llm-4/13">
<meta property="og:image" content="https://higiraffe.github.io/images/llm-4/14">
<meta property="og:image" content="https://higiraffe.github.io/images/llm-4/15">
<meta property="og:image" content="https://higiraffe.github.io/images/llm-4/16">
<meta property="og:image" content="https://higiraffe.github.io/images/llm-4/17">
<meta property="og:image" content="https://higiraffe.github.io/images/llm-4/18">
<meta property="og:image" content="https://higiraffe.github.io/images/llm-4/19">
<meta property="article:published_time" content="2024-03-30T11:35:07.000Z">
<meta property="article:modified_time" content="2024-04-18T16:07:24.765Z">
<meta property="article:author" content="Julian">
<meta property="article:tag" content="Artificial Intelligence">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://higiraffe.github.io/images/llm-4/5">
    
    
    <!--- Icon Part-->
    <link rel="icon" type="image/png" href="/images/favicon.ico" sizes="192x192">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.ico">
    <meta name="theme-color" content="#1890ff">
    <link rel="shortcut icon" href="/images/favicon.ico">
    <!--- Page Info-->
    
    <title>
        
            【学习笔记】vLLM -
        
        HiGiraffe
    </title>
    
<link rel="stylesheet" href="/css/style.css">


    
        
<link rel="stylesheet" href="/css/build/styles.css">

    

    
<link rel="stylesheet" href="/fonts/fonts.css">

    
<link rel="stylesheet" href="/fonts/Satoshi/satoshi.css">

    
<link rel="stylesheet" href="/fonts/Chillax/chillax.css">

    <!--- Font Part-->
    
        <link href="home_banner.custom_font.url" rel="stylesheet">
    
    
    
        <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@400;500;700&display=swap" rel="stylesheet">
    
    
        <link href="https://fonts.googleapis.com/css2?family=Inter&display=swap" rel="stylesheet">
    

    <!--- Inject Part-->
    
        
            
    
            
    
            
                
                    <style>.navbar-container .navbar-content .right .desktop .navbar-list .navbar-item, .navbar-container .navbar-content .right .desktop .navbar-list .navbar-item a i, .navbar-container .navbar-content .left .logo-title h1, .navbar-container .navbar-content .right .desktop .navbar-list .navbar-item.search i { color: #808080 !important; } </style>
                
    
    <script id="hexo-configurations">
    let Global = window.Global || {};
    Global.hexo_config = {"hostname":"higiraffe.github.io","root":"/","language":"en","path":"search.xml"};
    Global.theme_config = {"articles":{"style":{"font_size":"16px","line_height":1.5,"image_border_radius":"14px","image_alignment":"center","image_caption":false,"link_icon":true},"word_count":{"enable":true,"count":true,"min2read":true},"author_label":{"enable":false,"auto":false,"list":[]},"code_block":{"copy":true,"style":"mac","font":{"enable":false,"family":null,"url":null}},"toc":{"enable":true,"max_depth":3,"number":false,"expand":true,"init_open":true},"copyright":false,"lazyload":true,"recommendation":{"enable":false,"title":"推荐阅读","limit":3,"mobile_limit":2,"placeholder":"/images/wallhaven-wqery6-light.webp","skip_dirs":[]}},"colors":{"primary":"#1890ff","secondary":null},"global":{"fonts":{"chinese":{"enable":true,"family":"Noto Sans SC","url":"https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@400;500;700&display=swap"},"english":{"enable":true,"family":"Inter","url":"https://fonts.googleapis.com/css2?family=Inter&display=swap"}},"content_max_width":"1000px","sidebar_width":"210px","hover":{"shadow":true,"scale":true},"scroll_progress":{"bar":true,"percentage":true},"website_counter":{"url":"https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js","enable":false,"site_pv":false,"site_uv":false,"post_pv":false},"single_page":true,"open_graph":true,"google_analytics":{"enable":false,"id":null}},"home_banner":{"enable":true,"style":"fixed","image":{"light":"/images/qixingyan.jpg","dark":"/images/qixingyan.jpg"},"title":"A sutdent's learning journey","subtitle":{"text":["... and occasional confusion"],"hitokoto":{"enable":false,"api":"https://v1.hitokoto.cn"},"typing_speed":100,"backing_speed":80,"starting_delay":500,"backing_delay":1500,"loop":true,"smart_backspace":true},"text_color":{"light":"#d9d9d9","dark":"#bcbcbc"},"text_style":{"title_size":"3rem","subtitle_size":"1.5rem","line_height":1.2},"custom_font":{"enable":true,"family":"Noto Sans SC","url":"home_banner.custom_font.url"},"social_links":{"enable":true,"links":{"github":"https://github.com/hiGiraffe","instagram":null,"zhihu":null,"twitter":null,"email":"hiGiraffe@foxmail.com"},"qrs":null}},"plugins":{"feed":{"enable":false},"aplayer":{"enable":false,"type":"fixed","audios":[{"name":null,"artist":null,"url":null,"cover":null}]},"mermaid":{"enable":false,"version":"9.3.0"}},"version":"2.4.4","navbar":{"auto_hide":false,"color":{"left":"#f78736","right":"#367df7","transparency":35},"links":{"Home":{"path":"/","icon":"fa-regular fa-house"},"Archives":{"path":"/archives","icon":"fa-regular fa-archive"},"Resources":{"icon":"fa-regular fa-link","path":"/resources/"},"About":{"icon":"fa-regular fa-user","submenus":{"Me":"/about","Github":"https://github.com/hiGiraffe"}}},"search":{"enable":true,"preload":true}},"page_templates":{"friends_column":3,"tags_style":"blur"},"home":{"sidebar":{"enable":true,"position":"left","first_item":"menu","announcement":"That's great! Just remember, if your study notes start talking back to you, it might be time for a break!","links":null},"article_date_format":"auto","categories":{"enable":true,"limit":3},"tags":{"enable":true,"limit":1}},"footerStart":"2023/10/1 0:0:0"};
    Global.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
    Global.data_config = {"masonry":false};
  </script>
    
    <!--- Fontawesome Part-->
    
<link rel="stylesheet" href="/fontawesome/fontawesome.min.css">

    
<link rel="stylesheet" href="/fontawesome/brands.min.css">

    
<link rel="stylesheet" href="/fontawesome/solid.min.css">

    
<link rel="stylesheet" href="/fontawesome/regular.min.css">

    
    
    
    
<meta name="generator" content="Hexo 6.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
        <span class="pjax-progress-bar"></span>
        <span class="swup-progress-icon">
            <i class="fa-solid fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container" id="swup">

    

    <div class="main-content-container">


        <div class="main-content-header">
            <header class="navbar-container">
    
    <div class="navbar-content">
        <div class="left">
            
            <a class="logo-title" href="https://higiraffe.github.io/">
                
                HiGiraffe
                
            </a>
        </div>

        <div class="right">
            <!-- PC -->
            <div class="desktop">
                <ul class="navbar-list">
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/"  >
                                    
                                        
                                            <i class="fa-regular fa-house"></i>
                                        
                                        HOME
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/archives"  >
                                    
                                        
                                            <i class="fa-regular fa-archive"></i>
                                        
                                        ARCHIVES
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/resources/"  >
                                    
                                        
                                            <i class="fa-regular fa-link"></i>
                                        
                                        RESOURCES
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="has-dropdown" 
                                    href="#" onClick="return false;">
                                    
                                        
                                            <i class="fa-regular fa-user"></i>
                                        
                                        ABOUT&nbsp;<i class="fa-solid fa-chevron-down"></i>
                                    
                                </a>
                                <!-- Submenu -->
                                
                                    <ul class="sub-menu">
                                    
                                        <li>
                                        <a href="/about">ME
                                        </a>
                                        </li>
                                    
                                        <li>
                                        <a target="_blank" rel="noopener" href="https://github.com/hiGiraffe">GITHUB
                                        </a>
                                        </li>
                                    
                                    </ul>
                                
                            </li>
                    
                    
                        <li class="navbar-item search search-popup-trigger">
                            <i class="fa-solid fa-magnifying-glass"></i>
                        </li>
                    
                </ul>
            </div>
            <!-- Mobile -->
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fa-solid fa-magnifying-glass"></i></div>
                
                <div class="icon-item navbar-bar">
                    <div class="navbar-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <!-- Mobile drawer -->
    <div class="navbar-drawer w-full absolute top-0 left-0 bg-background-color">
        <ul class="drawer-navbar-list flex flex-col justify-start items-center">
            
                
                    <li class="drawer-navbar-item text-base my-1.5 flex justify-center items-center">
                        <a class="rounded-3xl py-1.5 px-5 hover:border hover:!text-primary active:!text-primary group " 
                        href="/"  >
                             
                                
                                    <i class="fa-regular fa-house"></i>
                                
                                HOME
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            
                
                    <li class="drawer-navbar-item text-base my-1.5 flex justify-center items-center">
                        <a class="rounded-3xl py-1.5 px-5 hover:border hover:!text-primary active:!text-primary group " 
                        href="/archives"  >
                             
                                
                                    <i class="fa-regular fa-archive"></i>
                                
                                ARCHIVES
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            
                
                    <li class="drawer-navbar-item text-base my-1.5 flex justify-center items-center">
                        <a class="rounded-3xl py-1.5 px-5 hover:border hover:!text-primary active:!text-primary group " 
                        href="/resources/"  >
                             
                                
                                    <i class="fa-regular fa-link"></i>
                                
                                RESOURCES
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            
                
                    <li class="drawer-navbar-item text-base my-1.5 flex justify-center items-center">
                        <a class="rounded-3xl py-1.5 px-5 hover:border hover:!text-primary active:!text-primary group has-dropdown" 
                        href="#" onClick="return false;">
                            
                                
                                    <i class="fa-regular fa-user"></i>
                                
                                ABOUT&nbsp;<i class="group-hover:rotate-180 transition-transform fa-solid fa-chevron-down"></i>
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                              
                        
                            <li class="text-base flex justify-center items-center hover:underline active:underline hover:underline-offset-1 rounded-3xl">
                                <a class="py-0.5" href="/about">ME</a>
                            </li>
                        
                            <li class="text-base flex justify-center items-center hover:underline active:underline hover:underline-offset-1 rounded-3xl">
                                <a class="py-0.5" target="_blank" rel="noopener" href="https://github.com/hiGiraffe">GITHUB</a>
                            </li>
                        
                    
            

        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="main-content-body">

            

            <div class="main-content">

                
                    <div class="post-page-container">
    <div class="article-content-container">

        <div class="article-title">
            
                <h1 class="article-title-regular">【学习笔记】vLLM</h1>
            
            </div>
            
                    
        
        
            <div class="article-header">
                <div class="avatar">
                    <img src="https://avatars.githubusercontent.com/u/146565245?v=4">
                </div>
                <div class="info">
                    <div class="author">
                        <span class="name">Julian</span>
                        
                    </div>
                    <div class="meta-info">
                        <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fa-regular fa-pen-fancy"></i>&nbsp;
        <span class="desktop">2024-03-30 19:35:07</span>
        <span class="mobile">2024-03-30 19:35:07</span>
        <span class="hover-info">Created</span>
    </span>
    
        <span class="article-date article-meta-item">
            <i class="fa-regular fa-wrench"></i>&nbsp;
            <span class="desktop">2024-04-19 00:07:24</span>
            <span class="mobile">2024-04-19 00:07:24</span>
            <span class="hover-info">Updated</span>
        </span>
    

    
        <span class="article-categories article-meta-item">
            <i class="fa-regular fa-folders"></i>&nbsp;
            <ul>
                
                
                    
                        
                        <li>
                            <a href="/categories/AI/">AI</a>&nbsp;
                        </li>
                    
                    
                
                    
                        
                            <li>></li>
                        
                        <li>
                            <a href="/categories/AI/LLM/">LLM</a>&nbsp;
                        </li>
                    
                    
                
            </ul>
        </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fa-regular fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/Artificial-Intelligence/">Artificial Intelligence</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
    
    
</div>

                    </div>
                </div>
            </div>
        

        


        <div class="article-content markdown-body">
            <a class="button  center regular" target="_blank" rel="noopener" href="https://arxiv.org/abs/2309.06180" title="vLLM arxiv论文"><i class="fa-solid fa-paperclip"></i> vLLM arxiv论文</a>

<a class="button  center regular" target="_blank" rel="noopener" href="https://blog.vllm.ai/2023/06/20/vllm.html" title="vLLM关于PagedAttention的博客"><i class="fa-solid fa-paperclip"></i> vLLM关于PagedAttention的博客</a>

<a class="button  center regular" target="_blank" rel="noopener" href="https://docs.vllm.ai/en/latest/" title="vLLM官方文档"><i class="fa-solid fa-paperclip"></i> vLLM官方文档</a>

<a class="button  center regular" target="_blank" rel="noopener" href="https://readpaper.feishu.cn/docx/EcZxdsf4uozCoixdU3NcW03snwV" title="国内博客"><i class="fa-solid fa-paperclip"></i> 国内博客</a>



<h1 id="预备知识"><a href="#预备知识" class="headerlink" title="预备知识"></a>预备知识</h1><h2 id="transformer的self-attention-layers"><a href="#transformer的self-attention-layers" class="headerlink" title="transformer的self-attention layers"></a>transformer的self-attention layers</h2><blockquote>
<p>For an input hidden state sequence <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="19.575ex" height="2.497ex" role="img" focusable="false" viewBox="0 -853.7 8652 1103.7"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(961,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(1461,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mo" transform="translate(1905.7,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="mo" transform="translate(2350.3,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="mo" transform="translate(2795,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="mo" transform="translate(3239.7,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(3684.3,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(4256.3,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(4856.3,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(5523.1,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g><g data-mml-node="msup" transform="translate(6467.9,0)"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="TeXAtom" transform="translate(792,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(600,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(1378,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g></g></g></g></svg></mjx-container> , a self-attention layer first applies linear transformations on each position 𝑖 to get the query, key, and value vectors:</p>
<p><img lazyload="" src="/images/loading.svg" data-src="/images/llm-4/5" alt="image-20240331111833960"></p>
<p>Then, the self-attention layer computes the attention score <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.666ex;" xmlns="http://www.w3.org/2000/svg" width="2.596ex" height="1.663ex" role="img" focusable="false" viewBox="0 -441 1147.3 735.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="TeXAtom" transform="translate(562,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(345,0)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g></g></g></g></svg></mjx-container> by multiplying the query vector at one position with all the key vectors before it and compute the output <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="1.837ex" height="1.355ex" role="img" focusable="false" viewBox="0 -441 812 598.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(518,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container> as the weighted average over the value vectors:</p>
<p><img lazyload="" src="/images/loading.svg" data-src="/images/llm-4/6" alt="image-20240331111955260"></p>
</blockquote>
<p>简而言之，先把每个位置的词算出其q k v，然后用注意力公式算出每两个词之间的a和每个词的o。</p>
<p>除此之外，transformer including the embedding layer, feed-forward layer, layer normalization, residual connection, output logit computation, and the query, key, and value transformation.</p>
<h2 id="KV-Cache"><a href="#KV-Cache" class="headerlink" title="KV Cache"></a>KV Cache</h2><blockquote>
<p>以GPT为代表的Decoder-Only自回归语言模型在生成每一个新的 token 时，接受所有之前生成的 tokens 作为输入。然而，对于这些先前生成的 tokens，每次生成新的 token 时都需要重新计算他们的表示，这个过程造成了大量的计算浪费。KV Cache 的引入就是为了解决这个问题。</p>
<p>KV Cache实质上是存储了之前计算过的 key-value 对用于下一个Token的生成。在 Transformer 结构中，self-attention 中的k_proj, v_proj会将输入的每个 token 转化为一个 key 和一个 value，然后使用这些 key-value 以及当前的query对来计算下一个 token。引入 KV Cache，我们就可以将之前生成的 tokens 对应的 key-value 对存储起来，当生成新的 token 时，<strong>直接从 KV Cache 中取出这些已经计算好的 key-value 对，再把当前token的key-value做一个连结在进行计算</strong>，这样就避免了KV的重复计算，大大提高了计算效率。</p>
</blockquote>
<p>KV Cache包含以下步骤</p>
<blockquote>
<p><strong>预填充阶段</strong>：在计算第一个输出token过程中，此时Cache是空的，计算时需要为每个 transformer layer 计算并保存key cache和value cache，在输出token时Cache完成填充；FLOPs同KV Cache关闭一致，存在大量gemm操作，推理速度慢，这时属于Compute-bound类型计算。</p>
<p><strong>KV Cache阶段</strong>：在计算第二个输出token至最后一个token过程中，此时Cache是有值的，每轮推理只需读取Cache，同时将当前轮计算出的新的Key、Value追加写入至Cache；FLOPs降低，gemm变为gemv操作，推理速度相对第一阶段变快，这时属于Memory-bound类型计算。</p>
</blockquote>
<blockquote>
<p>无KV Cache生成示例</p>
<p><img lazyload="" src="/images/loading.svg" data-src="/images/llm-4/3" alt="image-20240330213245722"></p>
</blockquote>
<blockquote>
<p>KV Cache生成示例</p>
<p><img lazyload="" src="/images/loading.svg" data-src="/images/llm-4/4" alt="image-20240330213306988"></p>
</blockquote>
<p>我们可以看到，使用了KV Cache节省了大量的重复计算。</p>
<h2 id="当前Batching-Techniques-for-LLMs"><a href="#当前Batching-Techniques-for-LLMs" class="headerlink" title="当前Batching Techniques for LLMs"></a>当前Batching Techniques for LLMs</h2><p>困境：</p>
<ul>
<li>请求可能在不同时间段到达</li>
<li>请求序列的长度不同</li>
</ul>
<p>目前方法：</p>
<ul>
<li>采用细粒度的批处理机制</li>
</ul>
<h2 id="Memory-Challenges-in-LLM-Serving"><a href="#Memory-Challenges-in-LLM-Serving" class="headerlink" title="Memory Challenges in LLM Serving"></a>Memory Challenges in LLM Serving</h2><p>挑战：</p>
<ul>
<li>KV cache太大了，且GPU的计算能力会比其内存增长得更快。</li>
<li>decoding算法越来越复杂，如何适配。</li>
<li>输入输出长度不同的情况下如何调度资源。</li>
</ul>
<h1 id="vLLM"><a href="#vLLM" class="headerlink" title="vLLM"></a>vLLM</h1><h2 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h2><p><strong>效果</strong>：</p>
<blockquote>
<p> PagedAttention, an attention algorithm inspired by the classical <strong>virtual memory</strong> and <strong>paging techniques</strong> in operating systems</p>
</blockquote>
<p>想法来源于虚拟内存和分页技术</p>
<blockquote>
<p>vLLM, an LLM serving system that achieves (1) <strong>near-zero waste</strong> in KV cache memory and (2) <strong>flexible sharing of KV cache</strong> within and across requests to further reduce memory usage.</p>
</blockquote>
<blockquote>
<p><img lazyload="" src="/images/loading.svg" data-src="/images/llm-4/1" alt="image-20240330194543256"></p>
</blockquote>
<p>左图就是vLLM将KV Cache控制在红色，且用一部分黄色进行激活。所以随着规模扩大，vLLM的内存使用量可以控制得更好。正如右图所示。</p>
<blockquote>
<p><img lazyload="" src="/images/loading.svg" data-src="/images/llm-4/2" alt="image-20240330194852044"></p>
</blockquote>
<p>内存资源浪费平均百分比图，可以看到vLLM的有效性。</p>
<h2 id="PagedAttention"><a href="#PagedAttention" class="headerlink" title="PagedAttention"></a>PagedAttention</h2><p><strong>特色：</strong>允许不连续的KV cache存储方式。方法是采用分块的方式。</p>
<blockquote>
<p><img lazyload="" src="/images/loading.svg" data-src="/images/llm-4/1.gif" alt="annimation0"></p>
</blockquote>
<p>当原文为 Alan Turing is a|computer scientist and mathmatician|renowned for …</p>
<p>其被分成三个块来完成，这三个块的物理内存不一样。</p>
<p>计算方式为</p>
<blockquote>
<p><img lazyload="" src="/images/loading.svg" data-src="/images/llm-4/7" alt="image-20240331114636223"></p>
</blockquote>
<p>这样就可以减少KV Cache的浪费，最多浪费3个空。（这也是为什么操作系统引入分页机制）</p>
<blockquote>
<p><img lazyload="" src="/images/loading.svg" data-src="/images/llm-4/2.gif" alt="fcc6f1bb-484e-43ab-8101-dc5dbbdbcd89"></p>
</blockquote>
<p>并且根据操作系统的<strong>写时共享机制</strong>，PagedAttention 可以当产生多个结果时，将下图中的intelligence is复制到多个块上。</p>
<blockquote>
<p><img lazyload="" src="/images/loading.svg" data-src="/images/llm-4/3.gif" alt="annimation3"></p>
</blockquote>
<p>还采用了<strong>束搜索机制</strong></p>
<blockquote>
<p><img lazyload="" src="/images/loading.svg" data-src="/images/llm-4/8" alt="image-20240331120042678"></p>
<p>这是一个束宽为2的<a class="link" target="_blank" rel="noopener" href="https://zh.d2l.ai/chapter_recurrent-modern/beam-search.html">束搜索样例 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>。选择最大的两个。</p>
<p><img lazyload="" src="/images/loading.svg" data-src="/images/llm-4/9" alt="image-20240331120357189"></p>
<p>在vLLM中，则是这种效果，跟上图非常相似。</p>
</blockquote>
<p>vLLM也考虑到<strong>共享前缀</strong>的问题。</p>
<blockquote>
<p><img lazyload="" src="/images/loading.svg" data-src="/images/llm-4/10" alt="image-20240331120631554"></p>
</blockquote>
<p>对于此类应用vLLM会共享前缀，只在Task Input上有差异。其实就是前文的分页机制。</p>
<h2 id="Scheduling-and-Preemption"><a href="#Scheduling-and-Preemption" class="headerlink" title="Scheduling and Preemption"></a>Scheduling and Preemption</h2><p>采用<strong>first-come-first-serve</strong> (<strong>FCFS</strong>)，先来先服务。</p>
<p>问题：</p>
<ul>
<li>假如满了，应该驱逐哪些块<ul>
<li>transformer特性→同一个序列的块要么一起被驱逐，要么一起留下。</li>
<li>假如有束搜索，其将序列分成了很多组，且存在内存共享，组内所有序列的块同时被调度。</li>
</ul>
</li>
<li>假如仍被需要，如何恢复被驱逐的块。<ul>
<li>交换。放到CPU内存中。</li>
<li>重新计算。因为解码时的令牌和用户提示链接起来成为新的提示，一次就可以生成KV Cache，所以会比之前算的块。</li>
</ul>
</li>
</ul>
<h2 id="Distributed-Execution"><a href="#Distributed-Execution" class="headerlink" title="Distributed Execution"></a>Distributed Execution</h2><blockquote>
<p>Specifically, the attention operator is split on the attention head dimension, each SPMD process takes care of a subset of attention heads in multi-head attention.</p>
</blockquote>
<p>VLLM是将注意力算子在注意力头维度上进行分割。</p>
<p>且由于每个模型的分片处理相同的输入标记集，所以vLLM采用的是集中式调度，一个Scheduler。</p>
<blockquote>
<p>This common mapping allows GPU workers to execute the model with the physical blocks provided by the scheduler for each input request. Although each GPU worker has the same physical block IDs, <strong>a worker only stores a portion of the KV cache for its corresponding attention heads.</strong></p>
</blockquote>
<p>由于头不同，管理起来是一样的，但是数据是不一样的。</p>
<blockquote>
<p><img lazyload="" src="/images/loading.svg" data-src="/images/llm-4/11" alt="image-20240331122203810"></p>
<ol>
<li><p>In each step, the scheduler first prepares the message with input token IDs for each request in the batch, as well as the block table for each request. </p>
</li>
<li><p>Next, the scheduler broadcasts this control message to the GPU workers. </p>
</li>
<li><p>Then, the GPU workers start to execute the model with the input token IDs. </p>
</li>
<li><p>In the attention layers, the GPU workers read the KV cache according to the block table in the control message. </p>
</li>
<li><p>During execution, the GPU workers synchronize the intermediate results with the all-reduce communication primitive without the coordination of the scheduler, as in [47]. </p>
</li>
<li><p>In the end, the GPU workers send the sampled tokens of this iteration back to the scheduler.</p>
</li>
</ol>
</blockquote>
<h1 id="源码解读"><a href="#源码解读" class="headerlink" title="源码解读"></a>源码解读</h1><a class="button  center regular" target="_blank" rel="noopener" href="https://github.com/hiGiraffe/vllm" title="源码笔记"><i class="fa-solid fa-paperclip"></i> 源码笔记</a>

<a class="button  center regular" target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/691045737" title="图解大模型计算加速系列：vLLM源码解析1，整体架构"><i class="fa-solid fa-paperclip"></i> 图解大模型计算加速系列：vLLM源码解析1，整体架构</a>

<a class="button  center regular" target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/692540949" title="图解大模型计算加速系列：vLLM源码解析2，调度器策略(Scheduler)"><i class="fa-solid fa-paperclip"></i> 图解大模型计算加速系列：vLLM源码解析2，调度器策略(Scheduler)</a>

<blockquote>
<p>在vLLM中，当我们使用离线批处理模式时，表面上是在做“同步”推理，也即batch_size是静态固定的。<strong>但推理内核引擎（LLMEngine）在实际运作时，batch_size是可以动态变更的</strong>：在每一个推理阶段（<strong>prefill算1个推理阶段，每个decode各算1个推理阶段</strong>）处理的batch size可以根据当下显存的实际使用情况而变动。</p>
<p>举个例子来说：</p>
<ul>
<li>给定一个很大的batch，此时尽管vLLM采用了PagedAttention这样的显存优化技术，我们的gpu依然无法同时处理这么大的batch。</li>
<li>所以batch中的每一条数据，会被先放到一个waiting队列中。vLLM会用自己的调度策略从waiting队列中依次取数，加入running队列中，直到它认为取出的这些数据将会打满它为1个推理阶段分配好的显存。此时waiting队列中可能还会剩一些数据。</li>
<li>在每1个推理阶段，vLLM对running队列中的数据做推理。如果这1个推理阶段执行完毕后，有的数据已经完成了生成（比如正常遇到<code>&lt;eos&gt;</code>了），就将这些完成的数据从running队列中移开，并释放它占据的物理块显存。</li>
<li>这时，waiting队列中的数据就可以继续append进running队列中，做下1个阶段的推理。</li>
<li>因此在每1个推理阶段，vLLM处理的batch size可能会动态变更。</li>
<li>将LLMEngine包装成离线批处理形式后，所有的数据必须等到一起做完推理才能返给我们。所以从体感上，我们可能很难感知到内核引擎的“动态”逻辑。</li>
</ul>
<p><strong>在vLLM中，即使是同步形式的离线批处理，其背后的内核引擎也是按动态batch的形式来实现的</strong></p>
<p><strong>正是因为LLMEngine这种“动态处理”的特性，才使得它同时也能成为异步在线服务的内核引擎</strong>：当一条条请求发来时，它们都先进入LLMEngine调度器（Scheduler）的waiting队列中（实际并不是直接进入waiting队列中的，而是在传给LLMEngine前先进入asyncio.Queue()中，然后再由LLMEngine调度进waiting队列中的，这些细节我们也放在后面说，这里不影响理解就行）。此时模型正常执行它的1个推理阶段，调度器也正常处理新来的请求。当模型准备执行下1个推理阶段时，调度器再根据设定的策略，决定哪些数据可以进入running队列进行推理。由于在线服务是异步的，先推理完成的数据就可以先发给客户端了（如果采用流式传输，也可以生成多少先发多少）。<br><strong>在这个过程中，vLLM通过PagedAttention技术和“先来先服务（FCFS），后来先抢占，gpu不够就先swap到cpu上”的调度策略，在1个推理阶段处理尽可能多的请求，解决高并发场景下的推理吞吐问题。这就是整个vLLM运作的核心思想。（对这行黑体字里的术语有疑惑的朋友，建议先看vLLM原理篇讲解）</strong></p>
</blockquote>
<blockquote>
<p><img lazyload="" src="/images/loading.svg" data-src="/images/llm-4/12" alt="img"></p>
</blockquote>
<blockquote>
<p>先来看**<code>LLMEngine</code>**：</p>
<ul>
<li><strong><code>add_request()</code><strong>：该方法将每一个请求包装成vLLM能处理的数据类型(SequenceGroup，后面我们会详细解释)，并将其加入调度器（Scheduler）的waiting队列中。</strong>在LLMEngine中，这个函数是按照“同步”的方式设计的</strong>，也就是它被设计为“遍历batch中的每条数据，然后做相应处理”。所以这个函数本身只适合批处理场景。在异步的online serving中将会把它重写成异步的形式。</li>
<li>**<code>abort_request</code>**：在推理过程中，并不是所有的请求都能有返回结果。比如客户端断开连接时，这个请求的推理就可以终止了（abort），这个函数就被用来做这个操作。</li>
<li><strong><code>step()</code>：负责执行1次推理过程（1个prefill算1个次推理，每个decode各算1次推理）</strong>。在这个函数中，vLLM的调度器会决定要送那些数据去执行本次推理，并负责给这些数据分配好物理块（这些信息都被作为metadata放在要送给模型做推理的数据中）。模型会根据这些信息，采用PagedAttention方法，实际完成推理。</li>
</ul>
</blockquote>
<h2 id="整体代码架构"><a href="#整体代码架构" class="headerlink" title="整体代码架构"></a>整体代码架构</h2><blockquote>
<p><img lazyload="" src="/images/loading.svg" data-src="/images/llm-4/13" alt="img"></p>
<h3 id="Centralized-Controller"><a href="#Centralized-Controller" class="headerlink" title="Centralized Controller"></a>Centralized Controller</h3><p>**Centralized Controller，也就是前文我们所说的调度器(Scheduler)**。它和LLMEngine所在的进程是同一个，且两者都是在CPU上的。</p>
<ul>
<li><strong>调度器的主要作用就是，在每1个推理阶段，决定要把哪些数据送给模型做推理，同时负责给这些模型分配KV Cache物理块</strong>。但要注意，它只是分配了物理块的id，而不是物理块本身。物理块的实际分配是模型在推理过程中根据物理块id来操作的，也就是CacheEngine做的事情。</li>
<li><strong>调度器下维护着BlockSpaceManager。它负责管理BlockAllocator（实际参与分配物理块的类）。BlockAllocator又分成gpu和cpu两种类型，分别管理这两类设备上的物理块</strong>。<strong>你可能会问，cpu上的物理块是什么呢</strong>？你还记得调度器有一个swap策略吗？当gpu上显存不足时，它会把后来的请求抢占，并将其相关的KV cache物理块全部都先swap（置换、卸载）在cpu上，等后续gpu显存充足时，再把它们加载回gpu上继续做相关请求的推理。所以在cpu上我们也需要一个管控物理块的BlockAllocator。<strong>实际代码实现时，Block相关的部分可不止这两个class，还有一些更复杂的逻辑细节。这个我们放在本系列后面的文章中讲解</strong>。</li>
</ul>
<h3 id="Distributed-Workers"><a href="#Distributed-Workers" class="headerlink" title="Distributed Workers"></a>Distributed Workers</h3><p>Distributed Workers，也就是分布式系统，你可以将每个worker理解成一块gpu。它的作用是将我们要使用的模型load到各块卡上（目前对单卡装不下的模型，vLLM支持tp/pp推理），然后对Controller传来的数据做1次推理，返回相关结果。我们来细看下这块：</p>
<ul>
<li><p><strong>Distributed Workers</strong>：图中绘制为Distributed Workers这个绿色块，<strong>其实按vLLM的源码内容，写成Executor会更合适一些</strong>。<strong>它就是所有Workers的管控中心</strong>，它指定了用什么方法管控这些Workers，负责分布式环境的初始化，目前支持的方法有：</p>
</li>
<li><ul>
<li>cpu_executor：（较少用），使用cpu做推理时可考虑</li>
<li>gpu_executor：单卡（world_size = 1）的情况下可用</li>
<li>ray_gpu_executor：使用ray这个分布式计算框架实现的executor，适用于多卡环境</li>
</ul>
</li>
<li><p><strong>Worker</strong>：<strong>在硬件上，它指gpu；在代码上，它指的是Worker实例（每个gpu上的进程维护自己的Worker实例）</strong>。在每个Worker实例中又管控着如下两个重要实例：</p>
</li>
<li><ul>
<li><strong>CacheEngine：</strong>负责管控gpu/cpu上的KV cache物理块（调度器的block manager只负责物理块id的分配，CacheEngine则是根据这个id分配结果实打实地在管理物理块中的数据）</li>
<li><strong>Worker.model</strong>：根据vLLM代码，这里写成<strong>model_runner</strong>会更合适一些。<strong>它负责加载模型，并执行推理</strong>。PagedAttention的相关逻辑，就维护这个实例关联的代码下。</li>
</ul>
</li>
</ul>
</blockquote>
<h2 id="运行逻辑"><a href="#运行逻辑" class="headerlink" title="运行逻辑"></a>运行逻辑</h2><blockquote>
<p><strong>在vLLM正式开始处理1条请求（也就是LLMEngine的调度器正式开始运作时），它需要做两件和初始化相关的事：</strong></p>
<ul>
<li><strong>加载模型</strong></li>
<li><strong>预分配显存</strong></li>
</ul>
<ol>
<li>模型加载</li>
</ol>
<p><img lazyload="" src="/images/loading.svg" data-src="/images/llm-4/14" alt="img"></p>
<p>这里在做的事很直观：把你的base model加载到worker上。如果你是online加载的，vLLM默认使用HuggingFace，你也可以在环境变量中把相关配置改成ModelScope。</p>
<ol start="2">
<li><p>预分配显存</p>
<p><img lazyload="" src="/images/loading.svg" data-src="/images/llm-4/15" alt="img"></p>
<p><strong>在模型部署的初始化阶段（推理正式开始前），vLLM会通过模拟实验的方式，来决定gpu/cpu上到底有多少个KV cache物理块可以分配给后续的请求们做推理。vLLM管这个步骤叫<code>determine_num_available_blocks</code>，跟文章中的不一样</strong></p>
<p><strong>（1）杜撰假数据</strong></p>
<p><strong>（2）用假数据模拟一次前向推理</strong></p>
<p><strong>我们现在想知道在1次推理过程中，可以分配多少的显存给KV cache。我们可以使用如下公式计算：</strong><br><strong>分配给KV cache显存 = gpu总显存 - 不使用KV cache做1次推理时的显存占用（包括模型本身和推理过程中的中间数据）</strong></p>
<p>对于“不使用KV cache做1次推理时的显存占用”，我们就可以用杜撰出来的假数据模拟一次前向推理来计算得出。在前向推理之后，我们把gpu上的缓存清一次，让它不要影响后续模型的正常推理。</p>
<p><strong>（3）计算可分配的KV cache物理块总数</strong></p>
<p>CPU上物理块总数也是同理，但与GPU不同的是，它不需要做模拟实验。CPU上可用的内存总数是用户通过参数传进来的（默认是4G）。也就是我们认为只能在这4G的空间上做swap。将上面公式中“分配给KV Cache的显存大小”替换成4G，就能得到CPU上物理块的数量。</p>
<p><strong>（4）将预分配的KV Cache加载到gpu上</strong></p>
<p><strong>当我们确定好KV Cache block的大小后，我们就可以创建empty tensor，将其先放置到gpu上，实现显存的预分配。以后这块显存就是专门用来做KV Cache的了。</strong>也正是因为这种预分配，你可能会发现在vLLM初始化后，显存的占用比你预想地要多（高过模型大小），这就是预分配起的作用。相关代码如下（帮助大家更好看一下KV cache tensor的shape）:</p>
</li>
</ol>
</blockquote>
<h2 id="Scheduler调度"><a href="#Scheduler调度" class="headerlink" title="Scheduler调度"></a>Scheduler调度</h2><blockquote>
<p><img lazyload="" src="/images/loading.svg" data-src="/images/llm-4/16" alt="img"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="/images/llm-4/17" alt="img"></p>
<p><strong>vLLM的调度策略中有一项叫做：后来先抢占（*Preemption*）</strong>。它是指在准备执行当前这1个推理阶段时，如果gpu上没有足够的资源对running队列中的全部数据完成下1次推理，我们就取出running队列中最后来的数据，将它的KV Cache swapped到CPU上，同时将这个数据从running移到swapped中。<strong>我们重复执行这个步骤，直到当前gpu上有足够的KV Cache空间留给剩在running中的全部数据为止。</strong></p>
</blockquote>
<h2 id="LLM函数"><a href="#LLM函数" class="headerlink" title="LLM函数"></a>LLM函数</h2><blockquote>
<p>当我们调用·<code>outputs = llm.generate(prompts, sampling_params)</code>时，<strong>它实际做了两件事情：</strong></p>
<ul>
<li><p><strong><code>_add_request</code><strong>：</strong>将输入数据传给LLMEngine</strong>，它具体做了如下事情：</p>
</li>
<li><ul>
<li><strong>把每1个prompt包装成一个SequenceGroup对象</strong>。从客户端角度看，1个请求可能包含多个prompts，例如离线批处理场景下你可以将1个batch理解成1个请求；但是从LLMEngine的角度看，1个prompt是1个请求，所以它会对输入数据进行预处理。在后文对SequenceGroup的讲解中，我们会来看vLLM这样做的意义。</li>
<li><strong>把包装成SequenceGroup对象的数据加入调度器（Scheduler）的waiting队列，等待处理</strong>。这一块相关的细节，我们放在后文说。</li>
</ul>
</li>
<li><p><strong><code>_run_engine</code><strong>：</strong>执行推理</strong>。只要调度器的waiting/running/swapped队列非空，我们就认为此时这批batch还没有做完推理，这时我们就会**调用LLMEngine的step()**函数，来完成1次调度以决定要送哪些数据去做推理。</p>
</li>
</ul>
<p><strong>所以，想要知道调度器的运作流程，我们只要从<code>LLMEngine</code>的<code>add_request()</code>和<code>step()</code>两个函数入手就好了</strong>。<strong>不过在正式进入这两个函数的讲解之前，我们先来看和输入数据一个问题：为什么要把每个prompt都包装成一个SequenceGroup实例？SequenceGroup又长什么样呢？</strong></p>
</blockquote>
<h2 id="SequenceGroup"><a href="#SequenceGroup" class="headerlink" title="SequenceGroup"></a>SequenceGroup</h2><blockquote>
<p><strong>可能出现”1个prompt -&gt; 多个outputs”的情况。那是否能设计一种办法，对1个prompt下所有的outputs进行集中管理，来方便vLLM更好做推理呢？</strong></p>
</blockquote>
<blockquote>
<h3 id="SequenceGroup的作用"><a href="#SequenceGroup的作用" class="headerlink" title="SequenceGroup的作用"></a>SequenceGroup的作用</h3><ul>
<li><p><strong>“1个prompt -&gt; 多个outputs”这样的结构组成一个<code>SequenceGroup</code>实例。</strong></p>
</li>
<li><p><strong>其中每组”prompt -&gt; output”组成一个序列（seq，属于<code>Sequence</code>实例），每个seq下有若干状态(status)属性，包括：</strong></p>
</li>
<li><ul>
<li><p><strong><code>WAITING</code>：</strong>正在waiting队列中。waiting队列中的序列都没有做过prefill。</p>
</li>
<li><p><strong><code>RUNNING</code>：</strong>正在running队列中，即已经开始做推理。</p>
</li>
<li><p><strong><code>SWAPPED</code>：</strong>正在swapped队列中，表示此时gpu资源不足，相关的seq_group被抢占，导致其暂停推理，相关的KV block被置换到cpu上（swap out），等待gpu资源充足时再置换回来重新计算（swap in）。</p>
</li>
<li><p><strong>若干和Finish相关的状态</strong>，表示该seq推理已经结束，具体包括：</p>
</li>
<li><ul>
<li><strong><code>FINISHED_STOPPED</code>：</strong>正常执行完毕，例如碰到<code>&lt;eos&gt;</code>符号，该seq的推理正常结束了</li>
<li>**<code>FINISHED_LENGTH_CAPPED</code>**：因为seq的长度达到最大长度限制，而结束推理</li>
<li>**<code>FINISHED_ABORTED</code>**：因不正常状态，而被终止的推理。例如客户端断开连接，则服务器会终止相关seq的推理</li>
<li>**<code>FINISHED_IGNORED</code>**：因prompt过长而被终止执行的推理。本质上也是受到长度限制</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>在vLLM中有一个重要假设：一个seq_group中的所有seq共享1个prompt。</strong></p>
</li>
</ul>
<p>例子：</p>
<ul>
<li><p><strong>在推理开始之前</strong>，这个seq_group下只有1条seq，它就是prompt，状态为waiting。</p>
</li>
<li><p><strong>在第1个推理阶段</strong>，调度器选中了这个seq_group，由于它的采样参数中<code>n = 4</code>，所以在做完prefill之后，它会生成4个seq，它们的状态都是running。</p>
</li>
<li><p><strong>在若干个推理阶段后，gpu上的资源不够了，这个seq_group不幸被调度器抢占（preemption）</strong>，它相关的KV block也被swap out到cpu上。此时所有seq的状态变为swapped。这里要注意，<strong>当一个seq_group被抢占时，对它的处理有两种方式：</strong></p>
</li>
<li><ul>
<li><strong>Swap：如果该seq_group下的seq数量 &gt; 1，此时会采取swap策略</strong>，即把seq_group下【所有】seq的KV block从gpu上卸载到cpu上。（seq数量比较多，直接把算出的KV block抛弃，比较可惜）</li>
<li><strong>Recomputation：如果该seq_group下的seq数量 = 1，此时会采取recomputation策略</strong>，即把该seq_group相关的物理块都释放掉，然后将它重新放回waiting队列中。等下次它被选中推理时，就是从prefill阶段开始重新推理了，因此被称为“重计算”。（seq数量少，重新计算KV block的成本不高）</li>
</ul>
</li>
</ul>
<p><strong>【注意，并不是每个seq_group都会经历抢占，具体要看调度器策略和gpu资源使用情况】</strong></p>
<ul>
<li><strong>又过了若干个推理阶段，gpu上的资源又充足了，此时执行swap in操作</strong>，将卸载到cpu上的KV block重新读到gpu上，继续对该seq_group做推理，此时seq的状态又变为running。</li>
<li><strong>又过了若干个推理阶段，该seq_group中有1个seq已经推理完成了，它的状态就被标记为finish</strong>，此后这条已经完成的seq将不参与调度。</li>
<li><strong>又过了若干个推理阶段，这个seq_group下所有的seq都已经完成推理了</strong>，这样就可以把它作为最终output返回了。</li>
</ul>
<p><img lazyload="" src="/images/loading.svg" data-src="/images/llm-4/18" alt="img"></p>
</blockquote>
<blockquote>
<p><strong>SequenceGroup:</strong></p>
<ul>
<li>**<code>self.seqs_dict</code>**：{seq_id: seq}，其中每个seq是一个Sequence对象。正如我们前文介绍的那样，一个seq_group下包含若干seqs</li>
<li>**<code>self.sampling_params</code>**：采样参数</li>
<li><strong><code>self.metrics</code><strong>：</strong>记录该seq_group相关的指标，例如该seq_group是什么时候被加入LLMEngine的（arrival_time）</strong>，该seq_group第一次被调度器选中调度是什么时候等等。调度器在选择时，会参考seq_groups们的这些指标来做决策。</li>
<li><strong><code>get_max_num_running_steps</code><strong>：</strong>该seq_group在剩余生命周期内并行running的最大seq数量</strong>。<strong>“剩余生命周期”指从此刻一直到seq_group中所有的seq都做完推理</strong>。举个例子来说，我们看2.2节配图中倒数第3个时刻，此时这个seq_group内所有的seq都还没结束推理，所以若调用这个方法，则返回值为4；再看倒数第2个时刻，此时有1个seq已经完成了推理，所以若调用这个方法，则返回值为3。在后续调度策略代码中，我们将经常看到这个方法被调用，目的是用于估计若当前对一个seq_group做推理，它将消耗多少gpu资源。</li>
</ul>
</blockquote>
<blockquote>
<p>Sequence:</p>
<p>对于一个seq，我们重点来看它的属性<code>self.logical_token_blocks</code>（逻辑块）和方法<code>_append_tokens_to_blocks</code>（生成逻辑块的方法）。<strong>在vLLM中，每个seq都单独维护一份属于自己的逻辑块，不同的逻辑块可以指向同一个物理块</strong>（此刻你一定很关心逻辑块和物理块是如何做映射的，我们会循序渐进地讲解这点，<strong>现在你可以先忽略映射方法，把目光聚焦于“一个seq的逻辑块长什么样，怎么初始化它的逻辑块”</strong>）</p>
<p>分配 _append_tokens_to_blocks</p>
</blockquote>
<h2 id="add-request"><a href="#add-request" class="headerlink" title="add_request()"></a>add_request()</h2><blockquote>
<p> 将seq_group添加进调度器waiting队列</p>
</blockquote>
<h2 id="step"><a href="#step" class="headerlink" title="step()"></a>step()</h2><p><strong>调度器结构</strong></p>
<blockquote>
<p><img lazyload="" src="/images/loading.svg" data-src="/images/llm-4/19" alt="img"></p>
<ul>
<li><p>**<code>self.waiting, self.running, self.swapped</code>**：这三个都是python的deque()实例（双端队列，允许你从队列两侧添加或删除元素）。</p>
</li>
<li><ul>
<li><strong>waiting队列用于存放所有还未开始做推理的seq_group</strong>，“未开始”指连prefill阶段都没有经历过。所以waiting队列中的seq_group只有一个seq，即是原始的prompt。</li>
<li><strong>running队列用于存放当前正在做推理的seq_group。更准确地说，它存放的是上1个推理阶段被送去做推理的seq_group们</strong>，在开始新一轮推理阶段时，调度器会根据本轮的筛选结果，更新running队列，即决定本轮要送哪些seq_group去做推理。</li>
<li><strong>swapped队列用于存放被抢占的seq_group</strong>。在2.2节中我们有提过，若一个seq_group被抢占，调度器会对它执行swap或recomputation操作，分别对应着将它送去swapped队列或waiting队列，在后文我们会详细分析抢占处理的代码</li>
</ul>
</li>
<li><p><strong><code>self.policy</code>：是vLLM自定义的一个Policy实例，</strong>目标是根据调度器总策略（<strong>FCFS</strong>，First Come First Serve，先来先服务）原则，<strong>对各个队列里的seq_group按照其arrival time进行排序</strong>。相关代码比较好读，所以这里我们只概述它的作用，后续不再介绍它的代码实现。</p>
</li>
<li><p><strong><code>self.prev_time</code><strong>：</strong>上一次调度发起的时间点，初始化为0。</strong>我们知道每执行1次推理阶段前，调度器都要做一次调度，这个变量存放的就是上次调度发起的时间点。</p>
</li>
<li><p><strong><code>self.prev_prompt</code><strong>：取值为True/False，初始化为False。</strong>若上一次调度时，调度器有从waiting队列中取出seq_group做推理，即为True，否则为False。</strong></p>
</li>
<li><p><strong><code>self.last_prompt_latency</code><strong>：</strong>记录“当前调度时刻（now） - 最后一次有从waiting队列中取数做推理的那个调度时刻”的差值</strong>（并不是每一次调度时，调度器一定都会从waiting队列中取seq_group，它可能依旧继续对running队列中的数据做推理），初始化为0。</p>
</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li><p><strong><code>BlockManager</code><strong>：</strong>物理块管理器</strong>。这也是vLLM自定义的一个class。截止本文写作时，vLLM提供了<code>BlockSpaceManagerV1</code>和<code>BlockSpaceManagerV2</code>两个版本的块管理器。V1是vLLM默认的版本，V2是改进版本（但还没开发完，例如不支持prefix caching等功能）。所以本文依然基于<code>BlockSpaceManagerV1</code>进行讲解。物理块管理器这个class下又维护着两个重要属性：</p>
</li>
<li><ul>
<li><strong><code>BlockAllocator</code>：物理块分配者，负责实际为seq做物理块的分配、释放、拷贝等操作。</strong>这也是我们后文要解读的对象。其下又分成<code>self.gpu_allocator</code>和<code>self.cpu_allocator</code>两种类型，分别管理gpu和cpu上的物理块。</li>
<li><strong><code>self.block_tables</code>：负责维护每个seq下的物理块列表，本质上它是一个字典，形式如<code>{seq_id: List[PhysicalTokenBlock]}</code>。</strong>注意，这里维护者【所有】seq_group下seq的物理块，而不是单独某一个seq的。因为整个调度器都是全局的，其下的BlockManager自然也是全局的。</li>
</ul>
</li>
<li><p><strong>BlockManager只负责管理和分配物理块，映射关系潜藏在seq中</strong>。理解这点对理解代码非常重要。</p>
</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li><p><strong>如果当前swapped队列为空，那就去检查是否能从waiting队列中调度seq_group，直到不满足调度条件为止（gpu空间不足，或waiting队列已为空等）</strong>。<strong>此时，1个推理阶段中，所有的seq_group都处在prefill阶段。</strong></p>
</li>
<li><p><strong>如果当前swapped队列非空，或者无法从waiting队列中调度任何seq_group时：</strong></p>
</li>
<li><ul>
<li>检查是否能从running队列中调度seq_group，直到不满足调度条件为止。</li>
<li>若本次无新的被抢占的seq_group，且swapped队列非空，就检查是否能从swapped队列中调度seq_group，直到不满足调度条件为止。</li>
</ul>
</li>
</ul>
<p><strong>此时，1个推理阶段中，所有的seq_group要么全来自running队列，要么来自running + swapped队列，它们都处在decode阶段。</strong></p>
<p><strong>至此我们要记住vLLM调度中非常重要的一点：在1个推理阶段中，所有的seq_group要么全部处在prefill阶段。要么全部处在decode阶段。</strong></p>
<p>你可能想问：<strong>为什么要以swapped是否非空为判断入口呢？</strong><br>这是因为，如果当前调度步骤中swapped队列非空，说明在之前的调度步骤中这些可怜的seq_group因为资源不足被抢占，而停滞了推理。所以<strong>根据FCFS规则，当gpu上有充足资源时，我们应该先考虑它们，而不是考虑waiting队列中新来的那些seq_group。</strong><br>同理，在图中你会发现，当我们进入对running队列的调度时（图中红色分支），我们会根据“<strong>本次调度是否有新的被抢占的seq_group</strong>”，来决定要不要调度swapped队列中的数据。这个理由也很简单：在本次调度中，我就是因为考虑到gpu空间不足的风险，我才新抢占了一批序列。既然存在这个风险，我就最好不要再去已有的swapped队列中继续调度seq_group了。</p>
</blockquote>
<h2 id="passed-delay"><a href="#passed-delay" class="headerlink" title="_passed_delay()"></a>_passed_delay()</h2><p>判断调度waiting队列的时间点</p>
<h2 id="can-allocate"><a href="#can-allocate" class="headerlink" title="can_allocate()"></a>can_allocate()</h2>
        </div>

        

        
            <ul class="post-tags-box">
                
                    <li class="tag-item">
                        <a href="/tags/Artificial-Intelligence/">#Artificial Intelligence</a>&nbsp;
                    </li>
                
            </ul>
        

        

        
            <div class="article-nav">
                
                    <div class="article-prev">
                        <a class="prev"
                        rel="prev"
                        href="/2024/04/01/hpc-ai-1/"
                        >
                            <span class="left arrow-icon flex justify-center items-center">
                                <i class="fa-solid fa-chevron-left"></i>
                            </span>
                            <span class="title flex justify-center items-center">
                                <span class="post-nav-title-item">Orca, A Distributed Serving System for Transformer-Based Generative Models</span>
                                <span class="post-nav-item">Prev posts</span>
                            </span>
                        </a>
                    </div>
                
                
                    <div class="article-next">
                        <a class="next"
                        rel="next"
                        href="/2024/03/29/nlp-6/"
                        >
                            <span class="title flex justify-center items-center">
                                <span class="post-nav-title-item">【学习笔记】自回归模型和GPT</span>
                                <span class="post-nav-item">Next posts</span>
                            </span>
                            <span class="right arrow-icon flex justify-center items-center">
                                <i class="fa-solid fa-chevron-right"></i>
                            </span>
                        </a>
                    </div>
                
            </div>
        


        
    </div>

    
        <div class="toc-content-container">
            <div class="post-toc-wrap">
    <div class="post-toc">
        <div class="toc-title">On this page</div>
        <div class="page-title">【学习笔记】vLLM</div>
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86"><span class="nav-text">预备知识</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#transformer%E7%9A%84self-attention-layers"><span class="nav-text">transformer的self-attention layers</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#KV-Cache"><span class="nav-text">KV Cache</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BD%93%E5%89%8DBatching-Techniques-for-LLMs"><span class="nav-text">当前Batching Techniques for LLMs</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Memory-Challenges-in-LLM-Serving"><span class="nav-text">Memory Challenges in LLM Serving</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#vLLM"><span class="nav-text">vLLM</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%88%E6%9E%9C"><span class="nav-text">效果</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#PagedAttention"><span class="nav-text">PagedAttention</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Scheduling-and-Preemption"><span class="nav-text">Scheduling and Preemption</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Distributed-Execution"><span class="nav-text">Distributed Execution</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB"><span class="nav-text">源码解读</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B4%E4%BD%93%E4%BB%A3%E7%A0%81%E6%9E%B6%E6%9E%84"><span class="nav-text">整体代码架构</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Centralized-Controller"><span class="nav-text">Centralized Controller</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Distributed-Workers"><span class="nav-text">Distributed Workers</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BF%90%E8%A1%8C%E9%80%BB%E8%BE%91"><span class="nav-text">运行逻辑</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Scheduler%E8%B0%83%E5%BA%A6"><span class="nav-text">Scheduler调度</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#LLM%E5%87%BD%E6%95%B0"><span class="nav-text">LLM函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SequenceGroup"><span class="nav-text">SequenceGroup</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#SequenceGroup%E7%9A%84%E4%BD%9C%E7%94%A8"><span class="nav-text">SequenceGroup的作用</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#add-request"><span class="nav-text">add_request()</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#step"><span class="nav-text">step()</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#passed-delay"><span class="nav-text">_passed_delay()</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#can-allocate"><span class="nav-text">can_allocate()</span></a></li></ol></li></ol>

    </div>
</div>
        </div>
    
</div>



                

            </div>

            

        </div>

        <div class="main-content-footer">
            <footer class="footer mt-5 py-5 h-auto text-base text-third-text-color relative border-t-2 border-t-border-color">
    <div class="info-container py-3 text-center">
        
        <div class="text-center">
            &copy;
            
              <span>2023</span>
              -
            
            2024&nbsp;&nbsp;<i class="fa-solid fa-heart fa-beat" style="--fa-animation-duration: 0.5s; color: #f54545"></i>&nbsp;&nbsp;<a href="/">Julian</a>
        </div>
        
        <div class="relative text-center lg:absolute lg:left-[20px] lg:top-1/2 lg:-translate-y-1/2 lg:text-left">
            <span class="lg:block text-sm">POWERED BY <?xml version="1.0" encoding="utf-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg class="relative top-[2px] inline-block align-baseline" version="1.1" id="圖層_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="1rem" height="1rem" viewBox="0 0 512 512" enable-background="new 0 0 512 512" xml:space="preserve"><path fill="#0E83CD" d="M256.4,25.8l-200,115.5L56,371.5l199.6,114.7l200-115.5l0.4-230.2L256.4,25.8z M349,354.6l-18.4,10.7l-18.6-11V275H200v79.6l-18.4,10.7l-18.6-11v-197l18.5-10.6l18.5,10.8V237h112v-79.6l18.5-10.6l18.5,10.8V354.6z"/></svg><a target="_blank" class="text-base" href="https://hexo.io">Hexo</a></span>
            <span class="text-sm lg:block">THEME&nbsp;<a class="text-base" target="_blank" href="https://github.com/EvanNotFound/hexo-theme-redefine">Redefine v2.4.4</a></span>
        </div>
        
        
            <div>
                Blog up for <span class="odometer" id="runtime_days" ></span> days <span class="odometer" id="runtime_hours"></span> hrs <span class="odometer" id="runtime_minutes"></span> Min <span class="odometer" id="runtime_seconds"></span> Sec
            </div>
        
        
            <script data-swup-reload-script>
                try {
                    function odometer_init() {
                    const elements = document.querySelectorAll('.odometer');
                    elements.forEach(el => {
                        new Odometer({
                            el,
                            format: '( ddd).dd',
                            duration: 200
                        });
                    });
                    }
                    odometer_init();
                } catch (error) {}
            </script>
        
        
            
                
        
                
        
        
    </div>  
</footer>
        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="article-tools-list">
        <!-- TOC aside toggle -->
        
            <li class="right-bottom-tools page-aside-toggle">
                <i class="fa-regular fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
    </ul>
</div>

        </div>
    

    <div class="right-side-tools-container">
        <div class="side-tools-container">
    <ul class="hidden-tools-list">
        <li class="right-bottom-tools tool-font-adjust-plus flex justify-center items-center">
            <i class="fa-regular fa-magnifying-glass-plus"></i>
        </li>

        <li class="right-bottom-tools tool-font-adjust-minus flex justify-center items-center">
            <i class="fa-regular fa-magnifying-glass-minus"></i>
        </li>

        <li class="right-bottom-tools tool-expand-width flex justify-center items-center">
            <i class="fa-regular fa-expand"></i>
        </li>

        <li class="right-bottom-tools tool-dark-light-toggle flex justify-center items-center">
            <i class="fa-regular fa-moon"></i>
        </li>

        <!-- rss -->
        

        

        <li class="right-bottom-tools tool-scroll-to-bottom flex justify-center items-center">
            <i class="fa-regular fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="visible-tools-list">
        <li class="right-bottom-tools toggle-tools-list flex justify-center items-center">
            <i class="fa-regular fa-cog fa-spin"></i>
        </li>
        
            <li class="right-bottom-tools tool-scroll-to-top flex justify-center items-center">
                <i class="arrow-up fas fa-arrow-up"></i>
                <span class="percent"></span>
            </li>
        
        
    </ul>
</div>

    </div>

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fa-solid fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="Search..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="popup-btn-close">
                <i class="fa-solid fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fa-solid fa-spinner fa-spin-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>


    
<script src="/js/libs/Swup.min.js"></script>

<script src="/js/libs/SwupSlideTheme.min.js"></script>

<script src="/js/libs/SwupScriptsPlugin.min.js"></script>

<script src="/js/libs/SwupProgressPlugin.min.js"></script>

<script src="/js/libs/SwupScrollPlugin.min.js"></script>

<script>
    const swup = new Swup({
        plugins: [
            new SwupScriptsPlugin({
                optin: true,
            }),
            new SwupProgressPlugin(),
            new SwupScrollPlugin({
                offset: 80,
            }),
            new SwupSlideTheme({
                mainElement: ".main-content-body",
            }),
        ],
        containers: ["#swup"],
    });

    swup.hooks.on("page:view", () => {
        Global.refresh();
    });

    // if (document.readyState === "complete") {
    //
    // } else {
    //     document.addEventListener("DOMContentLoaded", () => init());
    // }
</script>






<script src="/js/utils.js" type="module"></script>

<script src="/js/main.js" type="module"></script>

<script src="/js/layouts/navbarShrink.js" type="module"></script>

<script src="/js/tools/scrollTopBottom.js" type="module"></script>

<script src="/js/tools/lightDarkSwitch.js" type="module"></script>

<script src="/js/layouts/categoryList.js" type="module"></script>



    
<script src="/js/tools/localSearch.js"></script>




    
<script src="/js/tools/codeBlock.js"></script>




    
<script src="/js/layouts/lazyload.js"></script>




    
<script src="/js/tools/runtime.js"></script>

    
<script src="/js/libs/odometer.min.js"></script>

    
<link rel="stylesheet" href="/assets/odometer-theme-minimal.css">




  
<script src="/js/libs/Typed.min.js"></script>

  
<script src="/js/plugins/typed.js"></script>







<div class="post-scripts" data-swup-reload-script>
    
        
<script src="/js/libs/anime.min.js"></script>

        
<script src="/js/tools/tocToggle.js" type="module"></script>

<script src="/js/layouts/toc.js" type="module"></script>

<script src="/js/plugins/tabs.js" type="module"></script>

    
</div>


</body>
</html>
